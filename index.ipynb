{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Product                       60000 non-null  object\n",
      " 1   Consumer complaint narrative  60000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv(\"Bank_complaints.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(n = 10000, random_state=123)\n",
    "# Split the data into X and y\n",
    "y = df_sample.Product\n",
    "X = df_sample['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size= 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words = 2000)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary') \n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary') \n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "\n",
    "y_train_lb = lb.fit_transform(y_train_final)\n",
    "y_val_lb = lb.transform(y_val)\n",
    "y_test_lb = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(units = 50, activation= 'relu'))\n",
    "baseline_model.add(layers.Dense(units = 25, activation = 'relu'))\n",
    "\n",
    "baseline_model.add(layers.Dense(units = 7, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer = 'SGD',\n",
    "                      loss = 'categorical_crossentropy',\n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.9683 - accuracy: 0.1373 - val_loss: 1.9505 - val_accuracy: 0.1590\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9392 - accuracy: 0.1728 - val_loss: 1.9322 - val_accuracy: 0.1830\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9230 - accuracy: 0.1960 - val_loss: 1.9180 - val_accuracy: 0.2110\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.9081 - accuracy: 0.2147 - val_loss: 1.9040 - val_accuracy: 0.2410\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8921 - accuracy: 0.2435 - val_loss: 1.8888 - val_accuracy: 0.2680\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.8740 - accuracy: 0.2704 - val_loss: 1.8722 - val_accuracy: 0.2850\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8540 - accuracy: 0.2989 - val_loss: 1.8538 - val_accuracy: 0.3050\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8318 - accuracy: 0.3160 - val_loss: 1.8323 - val_accuracy: 0.3140\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8070 - accuracy: 0.3387 - val_loss: 1.8084 - val_accuracy: 0.3400\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.7795 - accuracy: 0.3640 - val_loss: 1.7806 - val_accuracy: 0.3630\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.7490 - accuracy: 0.3884 - val_loss: 1.7508 - val_accuracy: 0.3880\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7152 - accuracy: 0.4152 - val_loss: 1.7159 - val_accuracy: 0.4130\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.6784 - accuracy: 0.4385 - val_loss: 1.6812 - val_accuracy: 0.4400\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.6391 - accuracy: 0.4653 - val_loss: 1.6382 - val_accuracy: 0.4570\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5969 - accuracy: 0.4907 - val_loss: 1.5969 - val_accuracy: 0.4670\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.5529 - accuracy: 0.5095 - val_loss: 1.5525 - val_accuracy: 0.4920\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5067 - accuracy: 0.5328 - val_loss: 1.5072 - val_accuracy: 0.5020\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.4594 - accuracy: 0.5509 - val_loss: 1.4587 - val_accuracy: 0.5230\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.4117 - accuracy: 0.5699 - val_loss: 1.4110 - val_accuracy: 0.5500\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3641 - accuracy: 0.5867 - val_loss: 1.3668 - val_accuracy: 0.5610\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.3180 - accuracy: 0.5981 - val_loss: 1.3222 - val_accuracy: 0.5760\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.2731 - accuracy: 0.6121 - val_loss: 1.2801 - val_accuracy: 0.5870\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2303 - accuracy: 0.6212 - val_loss: 1.2409 - val_accuracy: 0.5960\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.1900 - accuracy: 0.6395 - val_loss: 1.2006 - val_accuracy: 0.6100\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.1513 - accuracy: 0.6471 - val_loss: 1.1688 - val_accuracy: 0.6150\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.1156 - accuracy: 0.6568 - val_loss: 1.1304 - val_accuracy: 0.6240\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0822 - accuracy: 0.6643 - val_loss: 1.0995 - val_accuracy: 0.6340\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0505 - accuracy: 0.6724 - val_loss: 1.0704 - val_accuracy: 0.6420\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0210 - accuracy: 0.6812 - val_loss: 1.0444 - val_accuracy: 0.6400\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.9945 - accuracy: 0.6883 - val_loss: 1.0209 - val_accuracy: 0.6480\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.9685 - accuracy: 0.6955 - val_loss: 0.9937 - val_accuracy: 0.6640\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9449 - accuracy: 0.6997 - val_loss: 0.9751 - val_accuracy: 0.6630\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.9223 - accuracy: 0.7048 - val_loss: 0.9553 - val_accuracy: 0.6610\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9015 - accuracy: 0.7111 - val_loss: 0.9335 - val_accuracy: 0.6740\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8818 - accuracy: 0.7140 - val_loss: 0.9173 - val_accuracy: 0.6800\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8633 - accuracy: 0.7220 - val_loss: 0.9011 - val_accuracy: 0.6770\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8458 - accuracy: 0.7273 - val_loss: 0.8868 - val_accuracy: 0.6860\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.8294 - accuracy: 0.7316 - val_loss: 0.8733 - val_accuracy: 0.6820\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8139 - accuracy: 0.7349 - val_loss: 0.8577 - val_accuracy: 0.6920\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7996 - accuracy: 0.7393 - val_loss: 0.8455 - val_accuracy: 0.7000\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7856 - accuracy: 0.7423 - val_loss: 0.8335 - val_accuracy: 0.7010\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7719 - accuracy: 0.7460 - val_loss: 0.8240 - val_accuracy: 0.7040\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7597 - accuracy: 0.7501 - val_loss: 0.8134 - val_accuracy: 0.7070\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7478 - accuracy: 0.7516 - val_loss: 0.8033 - val_accuracy: 0.6980\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.7368 - accuracy: 0.7545 - val_loss: 0.7945 - val_accuracy: 0.7110\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.7257 - accuracy: 0.7591 - val_loss: 0.7887 - val_accuracy: 0.7090\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7152 - accuracy: 0.7609 - val_loss: 0.7818 - val_accuracy: 0.7050\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7051 - accuracy: 0.7631 - val_loss: 0.7725 - val_accuracy: 0.7120\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.7681 - val_loss: 0.7664 - val_accuracy: 0.7120\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6867 - accuracy: 0.7692 - val_loss: 0.7558 - val_accuracy: 0.7200\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.7723 - val_loss: 0.7543 - val_accuracy: 0.7160\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6692 - accuracy: 0.7724 - val_loss: 0.7479 - val_accuracy: 0.7220\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6618 - accuracy: 0.7783 - val_loss: 0.7377 - val_accuracy: 0.7290\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6535 - accuracy: 0.7789 - val_loss: 0.7341 - val_accuracy: 0.7250\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.7841 - val_loss: 0.7290 - val_accuracy: 0.7290\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6384 - accuracy: 0.7883 - val_loss: 0.7232 - val_accuracy: 0.7260\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6313 - accuracy: 0.7895 - val_loss: 0.7223 - val_accuracy: 0.7240\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.7905 - val_loss: 0.7153 - val_accuracy: 0.7260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7936 - val_loss: 0.7091 - val_accuracy: 0.7320\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.7987 - val_loss: 0.7167 - val_accuracy: 0.7220\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.7947 - val_loss: 0.7045 - val_accuracy: 0.7310\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.7989 - val_loss: 0.7021 - val_accuracy: 0.7270\n",
      "Epoch 63/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.8020 - val_loss: 0.6996 - val_accuracy: 0.7330\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.8036 - val_loss: 0.6991 - val_accuracy: 0.7290\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.8033 - val_loss: 0.6919 - val_accuracy: 0.7350\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.8067 - val_loss: 0.6887 - val_accuracy: 0.7300\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.8103 - val_loss: 0.6860 - val_accuracy: 0.7390\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.8100 - val_loss: 0.6831 - val_accuracy: 0.7340\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.8151 - val_loss: 0.6881 - val_accuracy: 0.7330\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.8121 - val_loss: 0.6811 - val_accuracy: 0.7370\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.8184 - val_loss: 0.6801 - val_accuracy: 0.7360\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.8173 - val_loss: 0.6785 - val_accuracy: 0.7370\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.8227 - val_loss: 0.6786 - val_accuracy: 0.7380\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.8269 - val_loss: 0.6752 - val_accuracy: 0.7410\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.8247 - val_loss: 0.6739 - val_accuracy: 0.7370\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.8259 - val_loss: 0.6687 - val_accuracy: 0.7420\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.8276 - val_loss: 0.6700 - val_accuracy: 0.7380\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.8295 - val_loss: 0.6675 - val_accuracy: 0.7440\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.8324 - val_loss: 0.6646 - val_accuracy: 0.7400\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.8340 - val_loss: 0.6637 - val_accuracy: 0.7370\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.8356 - val_loss: 0.6655 - val_accuracy: 0.7380\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5008 - accuracy: 0.8364 - val_loss: 0.6635 - val_accuracy: 0.7400\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.8367 - val_loss: 0.6603 - val_accuracy: 0.7390\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4925 - accuracy: 0.8379 - val_loss: 0.6619 - val_accuracy: 0.7450\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4888 - accuracy: 0.8427 - val_loss: 0.6578 - val_accuracy: 0.7420\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4847 - accuracy: 0.8441 - val_loss: 0.6596 - val_accuracy: 0.7440\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4808 - accuracy: 0.8448 - val_loss: 0.6583 - val_accuracy: 0.7420\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4773 - accuracy: 0.8440 - val_loss: 0.6585 - val_accuracy: 0.7430\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4737 - accuracy: 0.8452 - val_loss: 0.6583 - val_accuracy: 0.7450\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.8476 - val_loss: 0.6569 - val_accuracy: 0.7480\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4659 - accuracy: 0.8484 - val_loss: 0.6588 - val_accuracy: 0.7410\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4625 - accuracy: 0.8481 - val_loss: 0.6514 - val_accuracy: 0.7420\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4586 - accuracy: 0.8513 - val_loss: 0.6538 - val_accuracy: 0.7430\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.8535 - val_loss: 0.6522 - val_accuracy: 0.7470\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4519 - accuracy: 0.8552 - val_loss: 0.6544 - val_accuracy: 0.7430\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4482 - accuracy: 0.8548 - val_loss: 0.6506 - val_accuracy: 0.7470\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.8560 - val_loss: 0.6516 - val_accuracy: 0.7430\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.8557 - val_loss: 0.6522 - val_accuracy: 0.7430\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8587 - val_loss: 0.6496 - val_accuracy: 0.7470\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.8596 - val_loss: 0.6527 - val_accuracy: 0.7470\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.8607 - val_loss: 0.6595 - val_accuracy: 0.7450\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8624 - val_loss: 0.6499 - val_accuracy: 0.7430\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8639 - val_loss: 0.6534 - val_accuracy: 0.7470\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8640 - val_loss: 0.6505 - val_accuracy: 0.7450\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8659 - val_loss: 0.6486 - val_accuracy: 0.7430\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8664 - val_loss: 0.6523 - val_accuracy: 0.7440\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.8685 - val_loss: 0.6498 - val_accuracy: 0.7450\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8685 - val_loss: 0.6515 - val_accuracy: 0.7470\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8689 - val_loss: 0.6512 - val_accuracy: 0.7460\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4028 - accuracy: 0.8713 - val_loss: 0.6543 - val_accuracy: 0.7470\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8723 - val_loss: 0.6552 - val_accuracy: 0.7390\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8743 - val_loss: 0.6507 - val_accuracy: 0.7460\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8757 - val_loss: 0.6561 - val_accuracy: 0.7440\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8744 - val_loss: 0.6546 - val_accuracy: 0.7430\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3882 - accuracy: 0.8771 - val_loss: 0.6562 - val_accuracy: 0.7390\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8807 - val_loss: 0.6512 - val_accuracy: 0.7410\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8799 - val_loss: 0.6545 - val_accuracy: 0.7450\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8809 - val_loss: 0.6544 - val_accuracy: 0.7380\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8807 - val_loss: 0.6543 - val_accuracy: 0.7440\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8821 - val_loss: 0.6575 - val_accuracy: 0.7450\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8821 - val_loss: 0.6526 - val_accuracy: 0.7410\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3686 - accuracy: 0.8840 - val_loss: 0.6516 - val_accuracy: 0.7450\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.8869 - val_loss: 0.6581 - val_accuracy: 0.7400\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8873 - val_loss: 0.6586 - val_accuracy: 0.7430\n",
      "Epoch 125/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.8884 - val_loss: 0.6554 - val_accuracy: 0.7430\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3579 - accuracy: 0.8887 - val_loss: 0.6543 - val_accuracy: 0.7490\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8904 - val_loss: 0.6609 - val_accuracy: 0.7410\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8887 - val_loss: 0.6570 - val_accuracy: 0.7400\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8929 - val_loss: 0.6580 - val_accuracy: 0.7470\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3475 - accuracy: 0.8923 - val_loss: 0.6585 - val_accuracy: 0.7440\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3448 - accuracy: 0.8943 - val_loss: 0.6603 - val_accuracy: 0.7440\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8944 - val_loss: 0.6606 - val_accuracy: 0.7350\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8959 - val_loss: 0.6621 - val_accuracy: 0.7380\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8971 - val_loss: 0.6679 - val_accuracy: 0.7440\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8973 - val_loss: 0.6690 - val_accuracy: 0.7420\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8987 - val_loss: 0.6620 - val_accuracy: 0.7430\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.9013 - val_loss: 0.6598 - val_accuracy: 0.7440\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.9007 - val_loss: 0.6650 - val_accuracy: 0.7370\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.9024 - val_loss: 0.6645 - val_accuracy: 0.7410\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3234 - accuracy: 0.9056 - val_loss: 0.6685 - val_accuracy: 0.7410\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3206 - accuracy: 0.9053 - val_loss: 0.6734 - val_accuracy: 0.7410\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.9053 - val_loss: 0.6684 - val_accuracy: 0.7410\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3163 - accuracy: 0.9060 - val_loss: 0.6678 - val_accuracy: 0.7420\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3144 - accuracy: 0.9085 - val_loss: 0.6738 - val_accuracy: 0.7370\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3121 - accuracy: 0.9084 - val_loss: 0.6706 - val_accuracy: 0.7390\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3099 - accuracy: 0.9100 - val_loss: 0.6752 - val_accuracy: 0.7320\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3074 - accuracy: 0.9104 - val_loss: 0.6728 - val_accuracy: 0.7420\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3053 - accuracy: 0.9117 - val_loss: 0.6723 - val_accuracy: 0.7390\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.9123 - val_loss: 0.6704 - val_accuracy: 0.7480\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3009 - accuracy: 0.9121 - val_loss: 0.6744 - val_accuracy: 0.7390\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(x = X_train_tokens, y = y_train_lb, \n",
    "                                        epochs = 150, batch_size=256, validation_data= (X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.9140\n",
      "----------\n",
      "Training Loss: 0.298 \n",
      "Training Accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.9140\n",
      "----------\n",
      "Test Loss: 0.298 \n",
      "Test Accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be3a572670>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "plt.plot(baseline_model_val.epoch, baseline_model_val_dict['loss'], label = \"Training Loss\")\n",
    "plt.plot(baseline_model_val.epoch, baseline_model_val_dict['val_loss'], label = \"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1be361b3fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets\n",
    "plt.plot(baseline_model_val.epoch, baseline_model_val_dict['accuracy'], label = \"Training Accuracy\")\n",
    "plt.plot(baseline_model_val.epoch, baseline_model_val_dict['val_accuracy'], label = \"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor = 'val_loss', patience = 10),\n",
    "                  ModelCheckpoint(filepath = \"best_model.h5\",  monitor = \"val_loss\", save_best_only = True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.9712 - acc: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0108s). Check your callbacks.\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.9691 - acc: 0.1277 - val_loss: 1.9655 - val_acc: 0.1220\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.9444 - acc: 0.1533 - val_loss: 1.9477 - val_acc: 0.1470\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9294 - acc: 0.1815 - val_loss: 1.9354 - val_acc: 0.1660\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.9170 - acc: 0.2035 - val_loss: 1.9250 - val_acc: 0.1960\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.9047 - acc: 0.2181 - val_loss: 1.9141 - val_acc: 0.2080\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.8918 - acc: 0.2345 - val_loss: 1.9032 - val_acc: 0.2190\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.8774 - acc: 0.2523 - val_loss: 1.8896 - val_acc: 0.2300\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.8612 - acc: 0.2705 - val_loss: 1.8743 - val_acc: 0.2470\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.8421 - acc: 0.2887 - val_loss: 1.8551 - val_acc: 0.2590\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.8200 - acc: 0.3129 - val_loss: 1.8326 - val_acc: 0.2830\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.7940 - acc: 0.3385 - val_loss: 1.8068 - val_acc: 0.3060\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.7634 - acc: 0.3611 - val_loss: 1.7747 - val_acc: 0.3290\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.7282 - acc: 0.3889 - val_loss: 1.7382 - val_acc: 0.3640\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.6876 - acc: 0.4188 - val_loss: 1.6979 - val_acc: 0.3930\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.6421 - acc: 0.4439 - val_loss: 1.6516 - val_acc: 0.4290\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.5917 - acc: 0.4685 - val_loss: 1.6002 - val_acc: 0.4650\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.5377 - acc: 0.4973 - val_loss: 1.5460 - val_acc: 0.4800\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.4809 - acc: 0.5181 - val_loss: 1.4896 - val_acc: 0.5100\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.4230 - acc: 0.5377 - val_loss: 1.4302 - val_acc: 0.5350\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3654 - acc: 0.5639 - val_loss: 1.3760 - val_acc: 0.5480\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.3099 - acc: 0.5872 - val_loss: 1.3215 - val_acc: 0.5700\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.2562 - acc: 0.6108 - val_loss: 1.2692 - val_acc: 0.5900\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.2054 - acc: 0.6275 - val_loss: 1.2252 - val_acc: 0.6010\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1575 - acc: 0.6472 - val_loss: 1.1788 - val_acc: 0.6230\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.1130 - acc: 0.6629 - val_loss: 1.1369 - val_acc: 0.6360\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0719 - acc: 0.6712 - val_loss: 1.0976 - val_acc: 0.6380\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0347 - acc: 0.6805 - val_loss: 1.0629 - val_acc: 0.6500\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0000 - acc: 0.6895 - val_loss: 1.0332 - val_acc: 0.6600\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9686 - acc: 0.6983 - val_loss: 1.0081 - val_acc: 0.6630\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9396 - acc: 0.7053 - val_loss: 0.9802 - val_acc: 0.6720\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9133 - acc: 0.7120 - val_loss: 0.9572 - val_acc: 0.6740\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8890 - acc: 0.7185 - val_loss: 0.9351 - val_acc: 0.6880\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8666 - acc: 0.7229 - val_loss: 0.9130 - val_acc: 0.6890\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8461 - acc: 0.7264 - val_loss: 0.8968 - val_acc: 0.6890\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8270 - acc: 0.7315 - val_loss: 0.8800 - val_acc: 0.6900\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8093 - acc: 0.7361 - val_loss: 0.8650 - val_acc: 0.6930\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7930 - acc: 0.7393 - val_loss: 0.8527 - val_acc: 0.6920\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.7818 - acc: 0.742 - 0s 8ms/step - loss: 0.7781 - acc: 0.7429 - val_loss: 0.8392 - val_acc: 0.6970\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7637 - acc: 0.7485 - val_loss: 0.8289 - val_acc: 0.6960\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.7504 - acc: 0.7491 - val_loss: 0.8140 - val_acc: 0.7030\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7380 - acc: 0.7504 - val_loss: 0.8041 - val_acc: 0.7000\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7264 - acc: 0.7556 - val_loss: 0.7980 - val_acc: 0.7000\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.7156 - acc: 0.7568 - val_loss: 0.7906 - val_acc: 0.7070\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.7048 - acc: 0.7601 - val_loss: 0.7782 - val_acc: 0.7010\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6950 - acc: 0.7636 - val_loss: 0.7771 - val_acc: 0.7120\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6860 - acc: 0.7648 - val_loss: 0.7680 - val_acc: 0.7120\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6767 - acc: 0.7664 - val_loss: 0.7613 - val_acc: 0.7030\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6683 - acc: 0.7671 - val_loss: 0.7558 - val_acc: 0.7120\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6599 - acc: 0.7735 - val_loss: 0.7568 - val_acc: 0.7110\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6522 - acc: 0.7763 - val_loss: 0.7476 - val_acc: 0.7110\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6447 - acc: 0.7765 - val_loss: 0.7389 - val_acc: 0.7160\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6374 - acc: 0.7795 - val_loss: 0.7390 - val_acc: 0.7190\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6304 - acc: 0.7820 - val_loss: 0.7325 - val_acc: 0.7220\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6236 - acc: 0.7847 - val_loss: 0.7305 - val_acc: 0.7260\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6172 - acc: 0.7857 - val_loss: 0.7224 - val_acc: 0.7240\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6102 - acc: 0.7879 - val_loss: 0.7238 - val_acc: 0.7130\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.6046 - acc: 0.7899 - val_loss: 0.7169 - val_acc: 0.7200\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5990 - acc: 0.7920 - val_loss: 0.7100 - val_acc: 0.7180\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5930 - acc: 0.7940 - val_loss: 0.7083 - val_acc: 0.7330\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5870 - acc: 0.7941 - val_loss: 0.7064 - val_acc: 0.7320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5819 - acc: 0.7977 - val_loss: 0.7049 - val_acc: 0.7290\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5760 - acc: 0.8003 - val_loss: 0.6985 - val_acc: 0.7280\n",
      "Epoch 63/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5710 - acc: 0.8029 - val_loss: 0.7001 - val_acc: 0.7270\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5660 - acc: 0.8057 - val_loss: 0.7028 - val_acc: 0.7310\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5610 - acc: 0.8043 - val_loss: 0.6950 - val_acc: 0.7250\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5558 - acc: 0.8089 - val_loss: 0.6952 - val_acc: 0.7370\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5506 - acc: 0.8101 - val_loss: 0.6909 - val_acc: 0.7280\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5464 - acc: 0.8125 - val_loss: 0.6934 - val_acc: 0.7390\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5413 - acc: 0.8144 - val_loss: 0.6923 - val_acc: 0.7440\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5371 - acc: 0.8151 - val_loss: 0.6870 - val_acc: 0.7370\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5324 - acc: 0.8165 - val_loss: 0.6839 - val_acc: 0.7420\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5279 - acc: 0.8175 - val_loss: 0.6841 - val_acc: 0.7330\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5233 - acc: 0.8220 - val_loss: 0.6834 - val_acc: 0.7400\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5191 - acc: 0.8231 - val_loss: 0.6762 - val_acc: 0.7410\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5151 - acc: 0.8225 - val_loss: 0.6776 - val_acc: 0.7390\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5107 - acc: 0.8257 - val_loss: 0.6747 - val_acc: 0.7400\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5068 - acc: 0.8273 - val_loss: 0.6756 - val_acc: 0.7440\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.5025 - acc: 0.8267 - val_loss: 0.6742 - val_acc: 0.7450\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4991 - acc: 0.8296 - val_loss: 0.6716 - val_acc: 0.7390\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4945 - acc: 0.8311 - val_loss: 0.6741 - val_acc: 0.7510\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4906 - acc: 0.8296 - val_loss: 0.6739 - val_acc: 0.7510\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4865 - acc: 0.8327 - val_loss: 0.6785 - val_acc: 0.7390\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4833 - acc: 0.8375 - val_loss: 0.6710 - val_acc: 0.7400\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4794 - acc: 0.8356 - val_loss: 0.6744 - val_acc: 0.7440\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4756 - acc: 0.8381 - val_loss: 0.6687 - val_acc: 0.7450\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4720 - acc: 0.8375 - val_loss: 0.6660 - val_acc: 0.7460\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4684 - acc: 0.8399 - val_loss: 0.6652 - val_acc: 0.7470\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4648 - acc: 0.8416 - val_loss: 0.6658 - val_acc: 0.7480\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4610 - acc: 0.8415 - val_loss: 0.6648 - val_acc: 0.7410\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4573 - acc: 0.8449 - val_loss: 0.6702 - val_acc: 0.7470\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4542 - acc: 0.8459 - val_loss: 0.6710 - val_acc: 0.7510\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4508 - acc: 0.8477 - val_loss: 0.6699 - val_acc: 0.7490\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4472 - acc: 0.8487 - val_loss: 0.6648 - val_acc: 0.7470\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4440 - acc: 0.8484 - val_loss: 0.6652 - val_acc: 0.7480\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4410 - acc: 0.8521 - val_loss: 0.6726 - val_acc: 0.7480\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4372 - acc: 0.8524 - val_loss: 0.6632 - val_acc: 0.7490\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4340 - acc: 0.8537 - val_loss: 0.6654 - val_acc: 0.7600\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4308 - acc: 0.8539 - val_loss: 0.6662 - val_acc: 0.7470\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4275 - acc: 0.8561 - val_loss: 0.6650 - val_acc: 0.7470\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4243 - acc: 0.8581 - val_loss: 0.6661 - val_acc: 0.7430\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4215 - acc: 0.8583 - val_loss: 0.6652 - val_acc: 0.7490\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4181 - acc: 0.8592 - val_loss: 0.6664 - val_acc: 0.7450\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4148 - acc: 0.8607 - val_loss: 0.6657 - val_acc: 0.7500\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4119 - acc: 0.8648 - val_loss: 0.6622 - val_acc: 0.7420\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4091 - acc: 0.8647 - val_loss: 0.6663 - val_acc: 0.7490\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4061 - acc: 0.8637 - val_loss: 0.6686 - val_acc: 0.7480\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4030 - acc: 0.8673 - val_loss: 0.6619 - val_acc: 0.7530\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3999 - acc: 0.8673 - val_loss: 0.6639 - val_acc: 0.7460\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3972 - acc: 0.8700 - val_loss: 0.6643 - val_acc: 0.7440\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3939 - acc: 0.8715 - val_loss: 0.6664 - val_acc: 0.7510\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3914 - acc: 0.8724 - val_loss: 0.6687 - val_acc: 0.7470\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3885 - acc: 0.8727 - val_loss: 0.6662 - val_acc: 0.7460\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3855 - acc: 0.8741 - val_loss: 0.6678 - val_acc: 0.7450\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3828 - acc: 0.8753 - val_loss: 0.6694 - val_acc: 0.7420\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3799 - acc: 0.8796 - val_loss: 0.6691 - val_acc: 0.7450\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3776 - acc: 0.8783 - val_loss: 0.6664 - val_acc: 0.7470\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.3747 - acc: 0.8792 - val_loss: 0.6673 - val_acc: 0.7490\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(x = X_train_tokens, y = y_train_lb, \n",
    "                                        epochs = 150, batch_size=256, validation_data= (X_val_tokens, y_val_lb), callbacks= early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 933us/step - loss: 0.3998 - acc: 0.8727\n",
      "Training Loss: 0.4 \n",
      "Training Accuracy: 0.873\n",
      "----------\n",
      "47/47 [==============================] - 0s 861us/step - loss: 0.5921 - acc: 0.7800\n",
      "Test Loss: 0.592 \n",
      "Test Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.5959 - acc: 0.1673 - val_loss: 2.5807 - val_acc: 0.1770\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.5662 - acc: 0.2037 - val_loss: 2.5573 - val_acc: 0.2010\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.5426 - acc: 0.2205 - val_loss: 2.5346 - val_acc: 0.2130\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.5189 - acc: 0.2332 - val_loss: 2.5113 - val_acc: 0.2390\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.4925 - acc: 0.2587 - val_loss: 2.4849 - val_acc: 0.2560\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.4627 - acc: 0.2785 - val_loss: 2.4549 - val_acc: 0.2790\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.4288 - acc: 0.3029 - val_loss: 2.4210 - val_acc: 0.2860\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.3912 - acc: 0.3277 - val_loss: 2.3830 - val_acc: 0.3210\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.3513 - acc: 0.3593 - val_loss: 2.3448 - val_acc: 0.3390\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.3088 - acc: 0.3835 - val_loss: 2.3038 - val_acc: 0.3570\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.2650 - acc: 0.4043 - val_loss: 2.2612 - val_acc: 0.3830\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.2199 - acc: 0.4297 - val_loss: 2.2180 - val_acc: 0.4010\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.1741 - acc: 0.4525 - val_loss: 2.1735 - val_acc: 0.4390\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.1276 - acc: 0.4837 - val_loss: 2.1309 - val_acc: 0.4500\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.0816 - acc: 0.5063 - val_loss: 2.0868 - val_acc: 0.4870\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.0357 - acc: 0.5343 - val_loss: 2.0431 - val_acc: 0.5110\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.9908 - acc: 0.5604 - val_loss: 2.0012 - val_acc: 0.5400\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9456 - acc: 0.5848 - val_loss: 1.9579 - val_acc: 0.5560\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.9010 - acc: 0.6057 - val_loss: 1.9163 - val_acc: 0.5710\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.8569 - acc: 0.6208 - val_loss: 1.8741 - val_acc: 0.5920\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8141 - acc: 0.6380 - val_loss: 1.8360 - val_acc: 0.6070\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7732 - acc: 0.6521 - val_loss: 1.7963 - val_acc: 0.6230\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.7335 - acc: 0.6623 - val_loss: 1.7576 - val_acc: 0.6390\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6956 - acc: 0.6731 - val_loss: 1.7232 - val_acc: 0.6470\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6598 - acc: 0.6853 - val_loss: 1.6887 - val_acc: 0.6620\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.6261 - acc: 0.6963 - val_loss: 1.6564 - val_acc: 0.6630\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.5941 - acc: 0.7055 - val_loss: 1.6276 - val_acc: 0.6760\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.5647 - acc: 0.7124 - val_loss: 1.6007 - val_acc: 0.6790\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.5368 - acc: 0.7197 - val_loss: 1.5740 - val_acc: 0.6810\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5108 - acc: 0.7248 - val_loss: 1.5526 - val_acc: 0.6890\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4869 - acc: 0.7268 - val_loss: 1.5282 - val_acc: 0.6960\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4636 - acc: 0.7344 - val_loss: 1.5083 - val_acc: 0.6990\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.4424 - acc: 0.7399 - val_loss: 1.4896 - val_acc: 0.7000\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4222 - acc: 0.7428 - val_loss: 1.4701 - val_acc: 0.7100\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.4035 - acc: 0.7476 - val_loss: 1.4548 - val_acc: 0.7060\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3863 - acc: 0.7495 - val_loss: 1.4390 - val_acc: 0.7090\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3691 - acc: 0.7531 - val_loss: 1.4266 - val_acc: 0.7070\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.3538 - acc: 0.7576 - val_loss: 1.4135 - val_acc: 0.7110\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3389 - acc: 0.7589 - val_loss: 1.3973 - val_acc: 0.7160\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3248 - acc: 0.7639 - val_loss: 1.3859 - val_acc: 0.7180\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.3113 - acc: 0.7661 - val_loss: 1.3750 - val_acc: 0.7150\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.2982 - acc: 0.7697 - val_loss: 1.3653 - val_acc: 0.7090\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.2863 - acc: 0.7717 - val_loss: 1.3549 - val_acc: 0.7230\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.2744 - acc: 0.7747 - val_loss: 1.3472 - val_acc: 0.7230\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.2631 - acc: 0.7784 - val_loss: 1.3412 - val_acc: 0.7250\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.2525 - acc: 0.7801 - val_loss: 1.3268 - val_acc: 0.7220\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.2419 - acc: 0.7831 - val_loss: 1.3191 - val_acc: 0.7230\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.2320 - acc: 0.7843 - val_loss: 1.3136 - val_acc: 0.7240\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.2222 - acc: 0.7868 - val_loss: 1.3061 - val_acc: 0.7240\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.2129 - acc: 0.7907 - val_loss: 1.2967 - val_acc: 0.7260\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.2039 - acc: 0.7933 - val_loss: 1.2908 - val_acc: 0.7250\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.1952 - acc: 0.7937 - val_loss: 1.2863 - val_acc: 0.7270\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1863 - acc: 0.7972 - val_loss: 1.2793 - val_acc: 0.7250\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.1778 - acc: 0.7995 - val_loss: 1.2742 - val_acc: 0.7230\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.1701 - acc: 0.8013 - val_loss: 1.2690 - val_acc: 0.7260\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.1620 - acc: 0.8028 - val_loss: 1.2650 - val_acc: 0.7290\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1544 - acc: 0.8039 - val_loss: 1.2567 - val_acc: 0.7280\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1470 - acc: 0.8059 - val_loss: 1.2502 - val_acc: 0.7240\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1394 - acc: 0.8095 - val_loss: 1.2479 - val_acc: 0.7280\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1323 - acc: 0.8129 - val_loss: 1.2433 - val_acc: 0.7280\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1249 - acc: 0.8116 - val_loss: 1.2404 - val_acc: 0.7310\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1184 - acc: 0.8132 - val_loss: 1.2321 - val_acc: 0.7270\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 7ms/step - loss: 1.1112 - acc: 0.8151 - val_loss: 1.2274 - val_acc: 0.7250\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1048 - acc: 0.8173 - val_loss: 1.2230 - val_acc: 0.7300\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0983 - acc: 0.8191 - val_loss: 1.2206 - val_acc: 0.7300\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0920 - acc: 0.8188 - val_loss: 1.2181 - val_acc: 0.7330\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0856 - acc: 0.8204 - val_loss: 1.2127 - val_acc: 0.7290\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0794 - acc: 0.8241 - val_loss: 1.2067 - val_acc: 0.7290\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0731 - acc: 0.8236 - val_loss: 1.2011 - val_acc: 0.7390\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0672 - acc: 0.8276 - val_loss: 1.1983 - val_acc: 0.7340\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0615 - acc: 0.8285 - val_loss: 1.1978 - val_acc: 0.7300\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0553 - acc: 0.8268 - val_loss: 1.1965 - val_acc: 0.7330\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0498 - acc: 0.8305 - val_loss: 1.1950 - val_acc: 0.7320\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0444 - acc: 0.8305 - val_loss: 1.1870 - val_acc: 0.7360\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0390 - acc: 0.8324 - val_loss: 1.1807 - val_acc: 0.7370\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0333 - acc: 0.8332 - val_loss: 1.1794 - val_acc: 0.7360\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0278 - acc: 0.8351 - val_loss: 1.1735 - val_acc: 0.7410\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.0224 - acc: 0.8337 - val_loss: 1.1732 - val_acc: 0.7420\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.0171 - acc: 0.8360 - val_loss: 1.1683 - val_acc: 0.7390\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.0122 - acc: 0.8400 - val_loss: 1.1700 - val_acc: 0.7410\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0069 - acc: 0.8405 - val_loss: 1.1654 - val_acc: 0.7410\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0019 - acc: 0.8415 - val_loss: 1.1627 - val_acc: 0.7420\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9967 - acc: 0.8424 - val_loss: 1.1653 - val_acc: 0.7360\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9919 - acc: 0.8428 - val_loss: 1.1572 - val_acc: 0.7430\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9870 - acc: 0.8432 - val_loss: 1.1525 - val_acc: 0.7450\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9821 - acc: 0.8465 - val_loss: 1.1537 - val_acc: 0.7420\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9774 - acc: 0.8468 - val_loss: 1.1482 - val_acc: 0.7440\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.9727 - acc: 0.8481 - val_loss: 1.1509 - val_acc: 0.7360\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9682 - acc: 0.8517 - val_loss: 1.1518 - val_acc: 0.7370\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9633 - acc: 0.8492 - val_loss: 1.1411 - val_acc: 0.7490\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9592 - acc: 0.8524 - val_loss: 1.1411 - val_acc: 0.7420\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9544 - acc: 0.8529 - val_loss: 1.1365 - val_acc: 0.7420\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9500 - acc: 0.8539 - val_loss: 1.1371 - val_acc: 0.7450\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9451 - acc: 0.8580 - val_loss: 1.1331 - val_acc: 0.7450\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9414 - acc: 0.8568 - val_loss: 1.1304 - val_acc: 0.7440\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9365 - acc: 0.8595 - val_loss: 1.1307 - val_acc: 0.7420\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9327 - acc: 0.8573 - val_loss: 1.1338 - val_acc: 0.7370\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9286 - acc: 0.8620 - val_loss: 1.1243 - val_acc: 0.7470\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.9241 - acc: 0.8617 - val_loss: 1.1213 - val_acc: 0.7450\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.9200 - acc: 0.8623 - val_loss: 1.1261 - val_acc: 0.7420\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9158 - acc: 0.8599 - val_loss: 1.1161 - val_acc: 0.7430\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9118 - acc: 0.8636 - val_loss: 1.1219 - val_acc: 0.7430\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.9077 - acc: 0.8645 - val_loss: 1.1125 - val_acc: 0.7480\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9039 - acc: 0.8659 - val_loss: 1.1096 - val_acc: 0.7430\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8995 - acc: 0.8664 - val_loss: 1.1110 - val_acc: 0.7440\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8956 - acc: 0.8696 - val_loss: 1.1149 - val_acc: 0.7410\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8921 - acc: 0.8677 - val_loss: 1.1042 - val_acc: 0.7430\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8879 - acc: 0.8707 - val_loss: 1.1054 - val_acc: 0.7490\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8841 - acc: 0.8712 - val_loss: 1.1037 - val_acc: 0.7450\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8802 - acc: 0.8719 - val_loss: 1.1018 - val_acc: 0.7400\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8765 - acc: 0.8744 - val_loss: 1.1034 - val_acc: 0.7500\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8731 - acc: 0.8752 - val_loss: 1.0996 - val_acc: 0.7450\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8690 - acc: 0.8760 - val_loss: 1.1019 - val_acc: 0.7420\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8655 - acc: 0.8763 - val_loss: 1.0932 - val_acc: 0.7460\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8619 - acc: 0.8773 - val_loss: 1.0937 - val_acc: 0.7430\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8587 - acc: 0.8768 - val_loss: 1.0948 - val_acc: 0.7430\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8547 - acc: 0.8779 - val_loss: 1.0889 - val_acc: 0.7430\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8513 - acc: 0.8795 - val_loss: 1.0898 - val_acc: 0.7460\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8479 - acc: 0.8805 - val_loss: 1.0940 - val_acc: 0.7390\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8446 - acc: 0.8800 - val_loss: 1.0887 - val_acc: 0.7430\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8409 - acc: 0.8816 - val_loss: 1.0869 - val_acc: 0.7420\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8376 - acc: 0.8817 - val_loss: 1.0846 - val_acc: 0.7390\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8342 - acc: 0.8827 - val_loss: 1.0812 - val_acc: 0.7450\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8307 - acc: 0.8837 - val_loss: 1.0790 - val_acc: 0.7430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8274 - acc: 0.8845 - val_loss: 1.0833 - val_acc: 0.7440\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.8242 - acc: 0.8857 - val_loss: 1.0746 - val_acc: 0.7440\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8208 - acc: 0.8875 - val_loss: 1.0809 - val_acc: 0.7450\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8176 - acc: 0.8872 - val_loss: 1.0759 - val_acc: 0.7420\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8144 - acc: 0.8897 - val_loss: 1.0759 - val_acc: 0.7420\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8109 - acc: 0.8896 - val_loss: 1.0682 - val_acc: 0.7430\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8080 - acc: 0.8904 - val_loss: 1.0739 - val_acc: 0.7460\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8050 - acc: 0.8897 - val_loss: 1.0684 - val_acc: 0.7430\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8017 - acc: 0.8909 - val_loss: 1.0672 - val_acc: 0.7490\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7988 - acc: 0.8915 - val_loss: 1.0674 - val_acc: 0.7480\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7953 - acc: 0.8924 - val_loss: 1.0680 - val_acc: 0.7480\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7929 - acc: 0.8925 - val_loss: 1.0643 - val_acc: 0.7480\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7895 - acc: 0.8927 - val_loss: 1.0630 - val_acc: 0.7490\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7866 - acc: 0.8945 - val_loss: 1.0613 - val_acc: 0.7460\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7835 - acc: 0.8932 - val_loss: 1.0593 - val_acc: 0.7470\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7806 - acc: 0.8952 - val_loss: 1.0611 - val_acc: 0.7420\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7777 - acc: 0.8963 - val_loss: 1.0576 - val_acc: 0.7470\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7749 - acc: 0.8972 - val_loss: 1.0580 - val_acc: 0.7460\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7716 - acc: 0.8991 - val_loss: 1.0657 - val_acc: 0.7470\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7696 - acc: 0.8975 - val_loss: 1.0550 - val_acc: 0.7490\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7665 - acc: 0.8987 - val_loss: 1.0563 - val_acc: 0.7520\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7632 - acc: 0.8999 - val_loss: 1.0568 - val_acc: 0.7480\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7607 - acc: 0.9011 - val_loss: 1.0515 - val_acc: 0.7520\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7581 - acc: 0.9009 - val_loss: 1.0534 - val_acc: 0.7470\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.7553 - acc: 0.9024 - val_loss: 1.0537 - val_acc: 0.7470\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7531 - acc: 0.9024 - val_loss: 1.0516 - val_acc: 0.7510\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras.regularizers import l2\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(units = 50, activation = 'relu', \n",
    "                          kernel_regularizer=l2(0.005), input_shape=(2000,)))\n",
    "L2_model.add(layers.Dense(units = 25, activation = 'relu', kernel_regularizer=l2(0.005)))\n",
    "\n",
    "# Add another hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['accuracy'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 16.0766 - acc: 0.1300 - val_loss: 15.6737 - val_acc: 0.1450\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 15.3073 - acc: 0.1735 - val_loss: 14.9258 - val_acc: 0.1800\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 14.5715 - acc: 0.2081 - val_loss: 14.2040 - val_acc: 0.2050\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 13.8595 - acc: 0.2304 - val_loss: 13.5048 - val_acc: 0.2060\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 13.1701 - acc: 0.2377 - val_loss: 12.8274 - val_acc: 0.2050\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 12.5016 - acc: 0.2400 - val_loss: 12.1703 - val_acc: 0.2140\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.8526 - acc: 0.2448 - val_loss: 11.5322 - val_acc: 0.2210\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.2224 - acc: 0.2548 - val_loss: 10.9122 - val_acc: 0.2310\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 10.6103 - acc: 0.2753 - val_loss: 10.3114 - val_acc: 0.2360\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 10.0178 - acc: 0.2905 - val_loss: 9.7301 - val_acc: 0.2770\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 9.4450 - acc: 0.3215 - val_loss: 9.1683 - val_acc: 0.3080\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 8.8922 - acc: 0.3419 - val_loss: 8.6270 - val_acc: 0.3170\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 8.3606 - acc: 0.3687 - val_loss: 8.1079 - val_acc: 0.3320\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.8513 - acc: 0.3828 - val_loss: 7.6103 - val_acc: 0.3520\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 7.3643 - acc: 0.4076 - val_loss: 7.1354 - val_acc: 0.3780\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.8990 - acc: 0.4251 - val_loss: 6.6823 - val_acc: 0.3890\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 6.4559 - acc: 0.4448 - val_loss: 6.2510 - val_acc: 0.4290\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 6.0347 - acc: 0.4673 - val_loss: 5.8424 - val_acc: 0.4580\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 5.6366 - acc: 0.4855 - val_loss: 5.4566 - val_acc: 0.4740\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 5.2607 - acc: 0.5015 - val_loss: 5.0930 - val_acc: 0.4810\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 4.9075 - acc: 0.5240 - val_loss: 4.7514 - val_acc: 0.4970\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.5763 - acc: 0.5387 - val_loss: 4.4330 - val_acc: 0.5210\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 4.2682 - acc: 0.5537 - val_loss: 4.1362 - val_acc: 0.5330\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 3.9828 - acc: 0.5685 - val_loss: 3.8637 - val_acc: 0.5390\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 3.7205 - acc: 0.5784 - val_loss: 3.6124 - val_acc: 0.5550\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 3.4801 - acc: 0.5917 - val_loss: 3.3837 - val_acc: 0.5590\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 3.2611 - acc: 0.5972 - val_loss: 3.1772 - val_acc: 0.5720\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 3.0645 - acc: 0.6080 - val_loss: 2.9891 - val_acc: 0.5910\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.8884 - acc: 0.6192 - val_loss: 2.8240 - val_acc: 0.6000\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.7331 - acc: 0.6225 - val_loss: 2.6792 - val_acc: 0.6060\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.5980 - acc: 0.6288 - val_loss: 2.5556 - val_acc: 0.6100\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 2.4836 - acc: 0.6303 - val_loss: 2.4493 - val_acc: 0.6290\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 2.3882 - acc: 0.6433 - val_loss: 2.3650 - val_acc: 0.6260\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 2.3109 - acc: 0.6471 - val_loss: 2.2955 - val_acc: 0.6430\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.2512 - acc: 0.6521 - val_loss: 2.2440 - val_acc: 0.6470\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.2067 - acc: 0.6607 - val_loss: 2.2063 - val_acc: 0.6530\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.1736 - acc: 0.6613 - val_loss: 2.1761 - val_acc: 0.6590\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.1465 - acc: 0.6640 - val_loss: 2.1504 - val_acc: 0.6590\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.1232 - acc: 0.6672 - val_loss: 2.1281 - val_acc: 0.6690\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.1008 - acc: 0.6692 - val_loss: 2.1069 - val_acc: 0.6680\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.0811 - acc: 0.6724 - val_loss: 2.0856 - val_acc: 0.6670\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 2.0617 - acc: 0.6715 - val_loss: 2.0664 - val_acc: 0.6710\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.0428 - acc: 0.6741 - val_loss: 2.0489 - val_acc: 0.6740\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 2.0253 - acc: 0.6739 - val_loss: 2.0309 - val_acc: 0.6700\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.0083 - acc: 0.6767 - val_loss: 2.0146 - val_acc: 0.6750\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9919 - acc: 0.6756 - val_loss: 1.9985 - val_acc: 0.6720\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9760 - acc: 0.6771 - val_loss: 1.9801 - val_acc: 0.6740\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9603 - acc: 0.6804 - val_loss: 1.9661 - val_acc: 0.6740\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9457 - acc: 0.6799 - val_loss: 1.9506 - val_acc: 0.6760\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9310 - acc: 0.6820 - val_loss: 1.9387 - val_acc: 0.6820\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9169 - acc: 0.6824 - val_loss: 1.9205 - val_acc: 0.6800\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9029 - acc: 0.6817 - val_loss: 1.9082 - val_acc: 0.6820\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8893 - acc: 0.6833 - val_loss: 1.8956 - val_acc: 0.6800\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8762 - acc: 0.6840 - val_loss: 1.8829 - val_acc: 0.6790\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8632 - acc: 0.6849 - val_loss: 1.8685 - val_acc: 0.6790\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8497 - acc: 0.6879 - val_loss: 1.8552 - val_acc: 0.6790\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.8371 - acc: 0.6860 - val_loss: 1.8435 - val_acc: 0.6800\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.8253 - acc: 0.6869 - val_loss: 1.8304 - val_acc: 0.6830\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.8137 - acc: 0.6879 - val_loss: 1.8187 - val_acc: 0.6770\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.8013 - acc: 0.6879 - val_loss: 1.8068 - val_acc: 0.6810\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7898 - acc: 0.6887 - val_loss: 1.7933 - val_acc: 0.6810\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.7780 - acc: 0.6884 - val_loss: 1.7837 - val_acc: 0.6820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.7670 - acc: 0.6887 - val_loss: 1.7711 - val_acc: 0.6830\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.7556 - acc: 0.6895 - val_loss: 1.7593 - val_acc: 0.6800\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.7449 - acc: 0.6897 - val_loss: 1.7495 - val_acc: 0.6870\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7346 - acc: 0.6904 - val_loss: 1.7407 - val_acc: 0.6830\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7238 - acc: 0.6913 - val_loss: 1.7317 - val_acc: 0.6820\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7138 - acc: 0.6905 - val_loss: 1.7175 - val_acc: 0.6850\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.7036 - acc: 0.6919 - val_loss: 1.7118 - val_acc: 0.6790\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6941 - acc: 0.6935 - val_loss: 1.7011 - val_acc: 0.6880\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6843 - acc: 0.6928 - val_loss: 1.6913 - val_acc: 0.6840\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6747 - acc: 0.6923 - val_loss: 1.6809 - val_acc: 0.6840\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6653 - acc: 0.6936 - val_loss: 1.6707 - val_acc: 0.6860\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6562 - acc: 0.6959 - val_loss: 1.6632 - val_acc: 0.6850\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6477 - acc: 0.6960 - val_loss: 1.6548 - val_acc: 0.6840\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6383 - acc: 0.6947 - val_loss: 1.6442 - val_acc: 0.6840\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6295 - acc: 0.6965 - val_loss: 1.6348 - val_acc: 0.6820\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.6208 - acc: 0.6992 - val_loss: 1.6286 - val_acc: 0.6870\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6123 - acc: 0.6981 - val_loss: 1.6172 - val_acc: 0.6840\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.6043 - acc: 0.6993 - val_loss: 1.6088 - val_acc: 0.6840\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5958 - acc: 0.6985 - val_loss: 1.6002 - val_acc: 0.6850\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5881 - acc: 0.7001 - val_loss: 1.5944 - val_acc: 0.6840\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5797 - acc: 0.7012 - val_loss: 1.5854 - val_acc: 0.6880\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5724 - acc: 0.7012 - val_loss: 1.5803 - val_acc: 0.6850\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5642 - acc: 0.7012 - val_loss: 1.5715 - val_acc: 0.6850\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5569 - acc: 0.7019 - val_loss: 1.5674 - val_acc: 0.6890\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5493 - acc: 0.7031 - val_loss: 1.5579 - val_acc: 0.6830\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5418 - acc: 0.7032 - val_loss: 1.5514 - val_acc: 0.6880\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.5344 - acc: 0.7052 - val_loss: 1.5404 - val_acc: 0.6850\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5272 - acc: 0.7051 - val_loss: 1.5365 - val_acc: 0.6870\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5196 - acc: 0.7047 - val_loss: 1.5261 - val_acc: 0.6880\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5129 - acc: 0.7079 - val_loss: 1.5211 - val_acc: 0.6870\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.5061 - acc: 0.7065 - val_loss: 1.5179 - val_acc: 0.6830\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4988 - acc: 0.7064 - val_loss: 1.5064 - val_acc: 0.6880\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4920 - acc: 0.7099 - val_loss: 1.5007 - val_acc: 0.6950\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4855 - acc: 0.7080 - val_loss: 1.4933 - val_acc: 0.6880\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4784 - acc: 0.7093 - val_loss: 1.4870 - val_acc: 0.6900\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4726 - acc: 0.7079 - val_loss: 1.4834 - val_acc: 0.6890\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4658 - acc: 0.7077 - val_loss: 1.4721 - val_acc: 0.6920\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4590 - acc: 0.7107 - val_loss: 1.4682 - val_acc: 0.6950\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4527 - acc: 0.7104 - val_loss: 1.4663 - val_acc: 0.6950\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4466 - acc: 0.7100 - val_loss: 1.4557 - val_acc: 0.6950\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4401 - acc: 0.7117 - val_loss: 1.4513 - val_acc: 0.6880\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.4339 - acc: 0.7117 - val_loss: 1.4431 - val_acc: 0.6950\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.4280 - acc: 0.7116 - val_loss: 1.4354 - val_acc: 0.6950\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.4219 - acc: 0.7127 - val_loss: 1.4338 - val_acc: 0.6970\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4160 - acc: 0.7141 - val_loss: 1.4258 - val_acc: 0.6940\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.4098 - acc: 0.7132 - val_loss: 1.4207 - val_acc: 0.6950\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4037 - acc: 0.7137 - val_loss: 1.4141 - val_acc: 0.6970\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3976 - acc: 0.7143 - val_loss: 1.4088 - val_acc: 0.6990\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3921 - acc: 0.7141 - val_loss: 1.4041 - val_acc: 0.7000\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3863 - acc: 0.7157 - val_loss: 1.3978 - val_acc: 0.7000\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3805 - acc: 0.7165 - val_loss: 1.3914 - val_acc: 0.6990\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3748 - acc: 0.7152 - val_loss: 1.3860 - val_acc: 0.6970\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3696 - acc: 0.7175 - val_loss: 1.3810 - val_acc: 0.7000\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3640 - acc: 0.7163 - val_loss: 1.3753 - val_acc: 0.6990\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3581 - acc: 0.7165 - val_loss: 1.3705 - val_acc: 0.7000\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3531 - acc: 0.7161 - val_loss: 1.3660 - val_acc: 0.6970\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3478 - acc: 0.7176 - val_loss: 1.3607 - val_acc: 0.7000\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3422 - acc: 0.7180 - val_loss: 1.3551 - val_acc: 0.7030\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3376 - acc: 0.7196 - val_loss: 1.3497 - val_acc: 0.7000\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3321 - acc: 0.7177 - val_loss: 1.3470 - val_acc: 0.7060\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3276 - acc: 0.7196 - val_loss: 1.3428 - val_acc: 0.7040\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3218 - acc: 0.7193 - val_loss: 1.3363 - val_acc: 0.6990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3172 - acc: 0.7199 - val_loss: 1.3292 - val_acc: 0.7040\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.3123 - acc: 0.7199 - val_loss: 1.3256 - val_acc: 0.7020\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3069 - acc: 0.7204 - val_loss: 1.3205 - val_acc: 0.7040\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3019 - acc: 0.7205 - val_loss: 1.3171 - val_acc: 0.7050\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2981 - acc: 0.7200 - val_loss: 1.3115 - val_acc: 0.7100\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2924 - acc: 0.7216 - val_loss: 1.3059 - val_acc: 0.7050\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2882 - acc: 0.7211 - val_loss: 1.3011 - val_acc: 0.7050\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2832 - acc: 0.7248 - val_loss: 1.3008 - val_acc: 0.7090\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2786 - acc: 0.7232 - val_loss: 1.2954 - val_acc: 0.7040\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2747 - acc: 0.7220 - val_loss: 1.2926 - val_acc: 0.7070\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2697 - acc: 0.7244 - val_loss: 1.2854 - val_acc: 0.7070\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2650 - acc: 0.7252 - val_loss: 1.2811 - val_acc: 0.7070\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2607 - acc: 0.7251 - val_loss: 1.2849 - val_acc: 0.7030\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2567 - acc: 0.7245 - val_loss: 1.2705 - val_acc: 0.7100\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.2446 - acc: 0.727 - 0s 4ms/step - loss: 1.2518 - acc: 0.7252 - val_loss: 1.2707 - val_acc: 0.7080\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2478 - acc: 0.7241 - val_loss: 1.2668 - val_acc: 0.7120\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2441 - acc: 0.7251 - val_loss: 1.2626 - val_acc: 0.7090\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2391 - acc: 0.7267 - val_loss: 1.2588 - val_acc: 0.7070\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2358 - acc: 0.7252 - val_loss: 1.2530 - val_acc: 0.7070\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2309 - acc: 0.7265 - val_loss: 1.2566 - val_acc: 0.7050\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2278 - acc: 0.7272 - val_loss: 1.2524 - val_acc: 0.7090\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2233 - acc: 0.7285 - val_loss: 1.2408 - val_acc: 0.7080\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2192 - acc: 0.7277 - val_loss: 1.2376 - val_acc: 0.7050\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2154 - acc: 0.7267 - val_loss: 1.2343 - val_acc: 0.7060\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2115 - acc: 0.7291 - val_loss: 1.2302 - val_acc: 0.7050\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.2077 - acc: 0.7285 - val_loss: 1.2275 - val_acc: 0.7050\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l1\n",
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(units = 50, activation = 'relu', input_shape=(2000,),\n",
    "                  kernel_regularizer=l1(0.005)))\n",
    "L1_model.add(layers.Dense(units = 25, activation = 'relu',\n",
    "                  kernel_regularizer=l1(0.005)))\n",
    "# Add a hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 1.9680 - acc: 0.1552 - val_loss: 1.9297 - val_acc: 0.2050\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.9461 - acc: 0.1704 - val_loss: 1.9198 - val_acc: 0.2130\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.9407 - acc: 0.1776 - val_loss: 1.9133 - val_acc: 0.2150\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.9352 - acc: 0.1855 - val_loss: 1.9078 - val_acc: 0.2210\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.9206 - acc: 0.1969 - val_loss: 1.9012 - val_acc: 0.2290\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.9161 - acc: 0.1987 - val_loss: 1.8946 - val_acc: 0.2320\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.9062 - acc: 0.2161 - val_loss: 1.8865 - val_acc: 0.2400\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.8989 - acc: 0.2125 - val_loss: 1.8781 - val_acc: 0.2450\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8915 - acc: 0.2273 - val_loss: 1.8686 - val_acc: 0.2570\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.8896 - acc: 0.2271 - val_loss: 1.8590 - val_acc: 0.2760\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8818 - acc: 0.2319 - val_loss: 1.8484 - val_acc: 0.2890\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8676 - acc: 0.2451 - val_loss: 1.8349 - val_acc: 0.2930\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.8496 - acc: 0.2596 - val_loss: 1.8189 - val_acc: 0.3010\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.8418 - acc: 0.2649 - val_loss: 1.8018 - val_acc: 0.3150\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.8287 - acc: 0.2733 - val_loss: 1.7823 - val_acc: 0.3470\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.8141 - acc: 0.2860 - val_loss: 1.7611 - val_acc: 0.3780\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.7984 - acc: 0.2965 - val_loss: 1.7404 - val_acc: 0.3920\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.7923 - acc: 0.2991 - val_loss: 1.7197 - val_acc: 0.4040\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.7787 - acc: 0.3029 - val_loss: 1.6979 - val_acc: 0.4090\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.7570 - acc: 0.3080 - val_loss: 1.6735 - val_acc: 0.4450\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.7331 - acc: 0.3293 - val_loss: 1.6480 - val_acc: 0.4740\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 1.7237 - acc: 0.3313 - val_loss: 1.6228 - val_acc: 0.4860\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.7006 - acc: 0.3449 - val_loss: 1.5959 - val_acc: 0.5110\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.6902 - acc: 0.3508 - val_loss: 1.5704 - val_acc: 0.5170\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.6662 - acc: 0.3701 - val_loss: 1.5471 - val_acc: 0.5230\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.6494 - acc: 0.3712 - val_loss: 1.5213 - val_acc: 0.5360\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.6279 - acc: 0.3831 - val_loss: 1.4951 - val_acc: 0.5470\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.5976 - acc: 0.3905 - val_loss: 1.4661 - val_acc: 0.5540\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.5888 - acc: 0.3991 - val_loss: 1.4459 - val_acc: 0.5640\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5767 - acc: 0.4020 - val_loss: 1.4213 - val_acc: 0.5840\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.5643 - acc: 0.4077 - val_loss: 1.3999 - val_acc: 0.5910\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.5427 - acc: 0.4199 - val_loss: 1.3767 - val_acc: 0.5890\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.5266 - acc: 0.4295 - val_loss: 1.3559 - val_acc: 0.6050\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.5077 - acc: 0.4343 - val_loss: 1.3320 - val_acc: 0.6080\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.4897 - acc: 0.4373 - val_loss: 1.3104 - val_acc: 0.6160\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.4798 - acc: 0.4507 - val_loss: 1.2884 - val_acc: 0.6330\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 1.4660 - acc: 0.4577 - val_loss: 1.2698 - val_acc: 0.6330\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 1.4527 - acc: 0.4585 - val_loss: 1.2504 - val_acc: 0.6390\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.4255 - acc: 0.4708 - val_loss: 1.2284 - val_acc: 0.6370\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.4252 - acc: 0.4712 - val_loss: 1.2146 - val_acc: 0.6470\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.3945 - acc: 0.4799 - val_loss: 1.1973 - val_acc: 0.6510\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.3934 - acc: 0.4840 - val_loss: 1.1785 - val_acc: 0.6540\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.3809 - acc: 0.4892 - val_loss: 1.1633 - val_acc: 0.6610\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.3611 - acc: 0.4936 - val_loss: 1.1473 - val_acc: 0.6670\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.3425 - acc: 0.4959 - val_loss: 1.1318 - val_acc: 0.6710\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.3267 - acc: 0.5073 - val_loss: 1.1118 - val_acc: 0.6790\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.3301 - acc: 0.5065 - val_loss: 1.1017 - val_acc: 0.6790\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 1.3168 - acc: 0.5128 - val_loss: 1.0862 - val_acc: 0.6730\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.3022 - acc: 0.5151 - val_loss: 1.0739 - val_acc: 0.6820\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.2939 - acc: 0.5193 - val_loss: 1.0617 - val_acc: 0.6820\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.2793 - acc: 0.5233 - val_loss: 1.0496 - val_acc: 0.6840\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 1.2672 - acc: 0.5364 - val_loss: 1.0380 - val_acc: 0.6920\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 1.2634 - acc: 0.5279 - val_loss: 1.0241 - val_acc: 0.6950\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.2515 - acc: 0.5339 - val_loss: 1.0150 - val_acc: 0.6920\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.2518 - acc: 0.5355 - val_loss: 1.0066 - val_acc: 0.6970\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.2356 - acc: 0.5391 - val_loss: 0.9993 - val_acc: 0.6990\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.2275 - acc: 0.5425 - val_loss: 0.9894 - val_acc: 0.7010\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.2269 - acc: 0.5404 - val_loss: 0.9859 - val_acc: 0.7050\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.2069 - acc: 0.5515 - val_loss: 0.9724 - val_acc: 0.7030\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 1.2126 - acc: 0.5512 - val_loss: 0.9631 - val_acc: 0.7070\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 1.1995 - acc: 0.5559 - val_loss: 0.9486 - val_acc: 0.7090\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 1.1816 - acc: 0.5583 - val_loss: 0.9427 - val_acc: 0.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1750 - acc: 0.5644 - val_loss: 0.9371 - val_acc: 0.7150\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1697 - acc: 0.5623 - val_loss: 0.9274 - val_acc: 0.7130\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1651 - acc: 0.5605 - val_loss: 0.9191 - val_acc: 0.7160\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.1618 - acc: 0.5676 - val_loss: 0.9142 - val_acc: 0.7160\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1584 - acc: 0.5687 - val_loss: 0.9089 - val_acc: 0.7170\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1597 - acc: 0.5692 - val_loss: 0.9043 - val_acc: 0.7210\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1452 - acc: 0.5811 - val_loss: 0.8987 - val_acc: 0.7190\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.1252 - acc: 0.5853 - val_loss: 0.8880 - val_acc: 0.7210\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 1.1243 - acc: 0.5831 - val_loss: 0.8806 - val_acc: 0.7180\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1136 - acc: 0.5837 - val_loss: 0.8740 - val_acc: 0.7170\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1317 - acc: 0.5773 - val_loss: 0.8696 - val_acc: 0.7240\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.1017 - acc: 0.5929 - val_loss: 0.8643 - val_acc: 0.7220\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.1021 - acc: 0.5881 - val_loss: 0.8578 - val_acc: 0.7190\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0842 - acc: 0.5989 - val_loss: 0.8511 - val_acc: 0.7260\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0837 - acc: 0.5991 - val_loss: 0.8453 - val_acc: 0.7240\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.1047 - acc: 0.5879 - val_loss: 0.8421 - val_acc: 0.7300\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 1.0901 - acc: 0.5967 - val_loss: 0.8404 - val_acc: 0.7290\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 1.0802 - acc: 0.6044 - val_loss: 0.8351 - val_acc: 0.7310\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 1.0746 - acc: 0.6004 - val_loss: 0.8288 - val_acc: 0.7290\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0692 - acc: 0.6003 - val_loss: 0.8227 - val_acc: 0.7370\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0631 - acc: 0.6051 - val_loss: 0.8215 - val_acc: 0.7360\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0519 - acc: 0.6003 - val_loss: 0.8177 - val_acc: 0.7370\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0516 - acc: 0.6104 - val_loss: 0.8131 - val_acc: 0.7340\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 1.0562 - acc: 0.6036 - val_loss: 0.8057 - val_acc: 0.7350\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 1.0454 - acc: 0.6133 - val_loss: 0.8041 - val_acc: 0.7360\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0379 - acc: 0.6212 - val_loss: 0.7982 - val_acc: 0.7350\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0390 - acc: 0.6143 - val_loss: 0.7926 - val_acc: 0.7370\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0301 - acc: 0.6244 - val_loss: 0.7936 - val_acc: 0.7390\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0270 - acc: 0.6188 - val_loss: 0.7873 - val_acc: 0.7390\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0129 - acc: 0.6191 - val_loss: 0.7836 - val_acc: 0.7410\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0348 - acc: 0.6185 - val_loss: 0.7852 - val_acc: 0.7410\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 1.0131 - acc: 0.6219 - val_loss: 0.7793 - val_acc: 0.7430\n",
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0027 - acc: 0.6303 - val_loss: 0.7776 - val_acc: 0.7380\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0074 - acc: 0.6248 - val_loss: 0.7722 - val_acc: 0.7400\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.0012 - acc: 0.6248 - val_loss: 0.7674 - val_acc: 0.7410\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9989 - acc: 0.6284 - val_loss: 0.7655 - val_acc: 0.7390\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9914 - acc: 0.6307 - val_loss: 0.7600 - val_acc: 0.7410\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9850 - acc: 0.6336 - val_loss: 0.7577 - val_acc: 0.7440\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9815 - acc: 0.6449 - val_loss: 0.7573 - val_acc: 0.7400\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9810 - acc: 0.6432 - val_loss: 0.7515 - val_acc: 0.7420\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9878 - acc: 0.6341 - val_loss: 0.7532 - val_acc: 0.7410\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9774 - acc: 0.6383 - val_loss: 0.7475 - val_acc: 0.7400\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9668 - acc: 0.6503 - val_loss: 0.7457 - val_acc: 0.7440\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9791 - acc: 0.6373 - val_loss: 0.7439 - val_acc: 0.7470\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9546 - acc: 0.6515 - val_loss: 0.7371 - val_acc: 0.7480\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9613 - acc: 0.6341 - val_loss: 0.7368 - val_acc: 0.7420\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.9762 - acc: 0.6389 - val_loss: 0.7378 - val_acc: 0.7460\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.9643 - acc: 0.6500 - val_loss: 0.7363 - val_acc: 0.7430\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9542 - acc: 0.6464 - val_loss: 0.7322 - val_acc: 0.7430\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9461 - acc: 0.6468 - val_loss: 0.7299 - val_acc: 0.7450\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9358 - acc: 0.6547 - val_loss: 0.7277 - val_acc: 0.7460\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9319 - acc: 0.6588 - val_loss: 0.7259 - val_acc: 0.7460\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9453 - acc: 0.6588 - val_loss: 0.7210 - val_acc: 0.7460\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9405 - acc: 0.6517 - val_loss: 0.7222 - val_acc: 0.7420\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9211 - acc: 0.6611 - val_loss: 0.7188 - val_acc: 0.7470\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9242 - acc: 0.6619 - val_loss: 0.7161 - val_acc: 0.7510\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9206 - acc: 0.6611 - val_loss: 0.7143 - val_acc: 0.7480\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9266 - acc: 0.6583 - val_loss: 0.7109 - val_acc: 0.7470\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9187 - acc: 0.6564 - val_loss: 0.7095 - val_acc: 0.7450\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9201 - acc: 0.6576 - val_loss: 0.7063 - val_acc: 0.7430\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9243 - acc: 0.6551 - val_loss: 0.7110 - val_acc: 0.7450\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9269 - acc: 0.6609 - val_loss: 0.7124 - val_acc: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9174 - acc: 0.6616 - val_loss: 0.7060 - val_acc: 0.7440\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.9018 - acc: 0.6660 - val_loss: 0.7026 - val_acc: 0.7470\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9039 - acc: 0.6700 - val_loss: 0.7006 - val_acc: 0.7460\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9059 - acc: 0.6661 - val_loss: 0.6990 - val_acc: 0.7460\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.9023 - acc: 0.6623 - val_loss: 0.6987 - val_acc: 0.7410\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8900 - acc: 0.6731 - val_loss: 0.6927 - val_acc: 0.7420\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8900 - acc: 0.6677 - val_loss: 0.6897 - val_acc: 0.7460\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8880 - acc: 0.6675 - val_loss: 0.6882 - val_acc: 0.7460\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.8823 - acc: 0.6705 - val_loss: 0.6880 - val_acc: 0.7450\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.8857 - acc: 0.6741 - val_loss: 0.6873 - val_acc: 0.7460\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.8956 - acc: 0.6669 - val_loss: 0.6892 - val_acc: 0.7430\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8816 - acc: 0.6761 - val_loss: 0.6853 - val_acc: 0.7440\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8790 - acc: 0.6711 - val_loss: 0.6815 - val_acc: 0.7470\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8751 - acc: 0.6767 - val_loss: 0.6809 - val_acc: 0.7460\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8804 - acc: 0.6776 - val_loss: 0.6820 - val_acc: 0.7440\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.8802 - acc: 0.6693 - val_loss: 0.6776 - val_acc: 0.7470\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.8650 - acc: 0.6772 - val_loss: 0.6755 - val_acc: 0.7450\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.8707 - acc: 0.6852 - val_loss: 0.6740 - val_acc: 0.7430\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8523 - acc: 0.6865 - val_loss: 0.6736 - val_acc: 0.7500\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.8671 - acc: 0.6811 - val_loss: 0.6750 - val_acc: 0.7470\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8608 - acc: 0.6779 - val_loss: 0.6729 - val_acc: 0.7490\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.8602 - acc: 0.6813 - val_loss: 0.6700 - val_acc: 0.7510\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8574 - acc: 0.6851 - val_loss: 0.6697 - val_acc: 0.7510\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8523 - acc: 0.6844 - val_loss: 0.6674 - val_acc: 0.7500\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8513 - acc: 0.6859 - val_loss: 0.6667 - val_acc: 0.7530\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.8353 - acc: 0.6907 - val_loss: 0.6642 - val_acc: 0.7480\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape = (2000,)))\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(units = 50, activation = 'relu'))\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(units = 25, activation = 'relu'))\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 1ms/step - loss: 0.5523 - acc: 0.8241\n",
      "Training Loss: 0.552 \n",
      "Training Accuracy: 0.824\n",
      "----------\n",
      "47/47 [==============================] - 0s 945us/step - loss: 0.6229 - acc: 0.7740\n",
      "Test Loss: 0.623 \n",
      "Test Accuracy: 0.774\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 1.8912 - acc: 0.2328 - val_loss: 1.8336 - val_acc: 0.2873\n",
      "Epoch 2/150\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 1.7214 - acc: 0.3475 - val_loss: 1.5900 - val_acc: 0.4187\n",
      "Epoch 3/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 1.4382 - acc: 0.5044 - val_loss: 1.2994 - val_acc: 0.5865\n",
      "Epoch 4/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 1.1694 - acc: 0.6236 - val_loss: 1.0687 - val_acc: 0.6695\n",
      "Epoch 5/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.9751 - acc: 0.6777 - val_loss: 0.9140 - val_acc: 0.7000\n",
      "Epoch 6/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.8513 - acc: 0.7080 - val_loss: 0.8230 - val_acc: 0.7188\n",
      "Epoch 7/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.7741 - acc: 0.7264 - val_loss: 0.7629 - val_acc: 0.7305\n",
      "Epoch 8/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.7228 - acc: 0.7405 - val_loss: 0.7244 - val_acc: 0.7390\n",
      "Epoch 9/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.6867 - acc: 0.7516 - val_loss: 0.6953 - val_acc: 0.7490\n",
      "Epoch 10/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.6588 - acc: 0.7594 - val_loss: 0.6787 - val_acc: 0.7517\n",
      "Epoch 11/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.6370 - acc: 0.7666 - val_loss: 0.6581 - val_acc: 0.7605\n",
      "Epoch 12/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.6192 - acc: 0.7723 - val_loss: 0.6472 - val_acc: 0.7673\n",
      "Epoch 13/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.6034 - acc: 0.7785 - val_loss: 0.6373 - val_acc: 0.7632\n",
      "Epoch 14/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.5903 - acc: 0.7841 - val_loss: 0.6231 - val_acc: 0.7765\n",
      "Epoch 15/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.5783 - acc: 0.7879 - val_loss: 0.6177 - val_acc: 0.7782\n",
      "Epoch 16/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.5676 - acc: 0.7921 - val_loss: 0.6139 - val_acc: 0.7725\n",
      "Epoch 17/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.5578 - acc: 0.7964 - val_loss: 0.6014 - val_acc: 0.7810\n",
      "Epoch 18/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5490 - acc: 0.7997 - val_loss: 0.5938 - val_acc: 0.7840\n",
      "Epoch 19/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5412 - acc: 0.8038 - val_loss: 0.5889 - val_acc: 0.7862\n",
      "Epoch 20/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5333 - acc: 0.8064 - val_loss: 0.5860 - val_acc: 0.7860\n",
      "Epoch 21/150\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.5263 - acc: 0.8089 - val_loss: 0.5807 - val_acc: 0.7895\n",
      "Epoch 22/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.5196 - acc: 0.8124 - val_loss: 0.5795 - val_acc: 0.7922\n",
      "Epoch 23/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5133 - acc: 0.8148 - val_loss: 0.5740 - val_acc: 0.7918\n",
      "Epoch 24/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.5073 - acc: 0.8167 - val_loss: 0.5698 - val_acc: 0.7955\n",
      "Epoch 25/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.5018 - acc: 0.8200 - val_loss: 0.5672 - val_acc: 0.7975\n",
      "Epoch 26/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4966 - acc: 0.8223 - val_loss: 0.5660 - val_acc: 0.7945\n",
      "Epoch 27/150\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.4918 - acc: 0.8235 - val_loss: 0.5609 - val_acc: 0.7983\n",
      "Epoch 28/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4869 - acc: 0.8256 - val_loss: 0.5608 - val_acc: 0.7987\n",
      "Epoch 29/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4823 - acc: 0.8282 - val_loss: 0.5571 - val_acc: 0.8010\n",
      "Epoch 30/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4780 - acc: 0.8293 - val_loss: 0.5552 - val_acc: 0.8015\n",
      "Epoch 31/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4739 - acc: 0.8315 - val_loss: 0.5533 - val_acc: 0.8010\n",
      "Epoch 32/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.4697 - acc: 0.8330 - val_loss: 0.5555 - val_acc: 0.8035\n",
      "Epoch 33/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4661 - acc: 0.8340 - val_loss: 0.5499 - val_acc: 0.8023\n",
      "Epoch 34/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.4626 - acc: 0.8352 - val_loss: 0.5502 - val_acc: 0.8045\n",
      "Epoch 35/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.4591 - acc: 0.8376 - val_loss: 0.5492 - val_acc: 0.8043\n",
      "Epoch 36/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4557 - acc: 0.8376 - val_loss: 0.5562 - val_acc: 0.8040\n",
      "Epoch 37/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4525 - acc: 0.8400 - val_loss: 0.5444 - val_acc: 0.8073\n",
      "Epoch 38/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4494 - acc: 0.8423 - val_loss: 0.5443 - val_acc: 0.8087\n",
      "Epoch 39/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4466 - acc: 0.8419 - val_loss: 0.5458 - val_acc: 0.8105\n",
      "Epoch 40/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4434 - acc: 0.8438 - val_loss: 0.5479 - val_acc: 0.8052\n",
      "Epoch 41/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4409 - acc: 0.8451 - val_loss: 0.5436 - val_acc: 0.8080\n",
      "Epoch 42/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4381 - acc: 0.8456 - val_loss: 0.5481 - val_acc: 0.8098\n",
      "Epoch 43/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4353 - acc: 0.8468 - val_loss: 0.5437 - val_acc: 0.8127\n",
      "Epoch 44/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4327 - acc: 0.8481 - val_loss: 0.5401 - val_acc: 0.8095\n",
      "Epoch 45/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4300 - acc: 0.8487 - val_loss: 0.5391 - val_acc: 0.8115\n",
      "Epoch 46/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4277 - acc: 0.8496 - val_loss: 0.5410 - val_acc: 0.8102\n",
      "Epoch 47/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4251 - acc: 0.8507 - val_loss: 0.5456 - val_acc: 0.8087\n",
      "Epoch 48/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4230 - acc: 0.8514 - val_loss: 0.5409 - val_acc: 0.8098\n",
      "Epoch 49/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.4203 - acc: 0.852 - 1s 7ms/step - loss: 0.4208 - acc: 0.8523 - val_loss: 0.5388 - val_acc: 0.8105\n",
      "Epoch 50/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.4188 - acc: 0.8533 - val_loss: 0.5429 - val_acc: 0.8102\n",
      "Epoch 51/150\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.4166 - acc: 0.8535 - val_loss: 0.5387 - val_acc: 0.8080\n",
      "Epoch 52/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4146 - acc: 0.8541 - val_loss: 0.5399 - val_acc: 0.8135\n",
      "Epoch 53/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4125 - acc: 0.8562 - val_loss: 0.5392 - val_acc: 0.8102\n",
      "Epoch 54/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4108 - acc: 0.8564 - val_loss: 0.5386 - val_acc: 0.8110\n",
      "Epoch 55/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4083 - acc: 0.8576 - val_loss: 0.5399 - val_acc: 0.8105\n",
      "Epoch 56/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4067 - acc: 0.8573 - val_loss: 0.5413 - val_acc: 0.8098\n",
      "Epoch 57/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4049 - acc: 0.8580 - val_loss: 0.5413 - val_acc: 0.8085\n",
      "Epoch 58/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4028 - acc: 0.8594 - val_loss: 0.5420 - val_acc: 0.8085\n",
      "Epoch 59/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.4012 - acc: 0.8594 - val_loss: 0.5393 - val_acc: 0.8123\n",
      "Epoch 60/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3996 - acc: 0.8604 - val_loss: 0.5399 - val_acc: 0.8112\n",
      "Epoch 61/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3977 - acc: 0.8615 - val_loss: 0.5425 - val_acc: 0.8112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3961 - acc: 0.8609 - val_loss: 0.5403 - val_acc: 0.8108\n",
      "Epoch 63/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3944 - acc: 0.8621 - val_loss: 0.5415 - val_acc: 0.8098\n",
      "Epoch 64/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3929 - acc: 0.8633 - val_loss: 0.5432 - val_acc: 0.8112\n",
      "Epoch 65/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3914 - acc: 0.8636 - val_loss: 0.5435 - val_acc: 0.8085\n",
      "Epoch 66/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3898 - acc: 0.8636 - val_loss: 0.5426 - val_acc: 0.8077\n",
      "Epoch 67/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3882 - acc: 0.8644 - val_loss: 0.5410 - val_acc: 0.8112\n",
      "Epoch 68/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3868 - acc: 0.8649 - val_loss: 0.5420 - val_acc: 0.8098\n",
      "Epoch 69/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3854 - acc: 0.8651 - val_loss: 0.5479 - val_acc: 0.8062\n",
      "Epoch 70/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3838 - acc: 0.8655 - val_loss: 0.5460 - val_acc: 0.8117\n",
      "Epoch 71/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3825 - acc: 0.8666 - val_loss: 0.5437 - val_acc: 0.8115\n",
      "Epoch 72/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3808 - acc: 0.8669 - val_loss: 0.5437 - val_acc: 0.8108\n",
      "Epoch 73/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3796 - acc: 0.8674 - val_loss: 0.5437 - val_acc: 0.8105\n",
      "Epoch 74/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3783 - acc: 0.8679 - val_loss: 0.5474 - val_acc: 0.8077\n",
      "Epoch 75/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3765 - acc: 0.8692 - val_loss: 0.5470 - val_acc: 0.8065\n",
      "Epoch 76/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3756 - acc: 0.8684 - val_loss: 0.5539 - val_acc: 0.8055\n",
      "Epoch 77/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3743 - acc: 0.8698 - val_loss: 0.5515 - val_acc: 0.8125\n",
      "Epoch 78/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3732 - acc: 0.8701 - val_loss: 0.5537 - val_acc: 0.8040\n",
      "Epoch 79/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3717 - acc: 0.8702 - val_loss: 0.5492 - val_acc: 0.8083\n",
      "Epoch 80/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3706 - acc: 0.8707 - val_loss: 0.5500 - val_acc: 0.8065\n",
      "Epoch 81/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3696 - acc: 0.8704 - val_loss: 0.5516 - val_acc: 0.8098\n",
      "Epoch 82/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3679 - acc: 0.8713 - val_loss: 0.5540 - val_acc: 0.8070\n",
      "Epoch 83/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3670 - acc: 0.8714 - val_loss: 0.5527 - val_acc: 0.8098\n",
      "Epoch 84/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3655 - acc: 0.8728 - val_loss: 0.5490 - val_acc: 0.8095\n",
      "Epoch 85/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3644 - acc: 0.8731 - val_loss: 0.5529 - val_acc: 0.8087\n",
      "Epoch 86/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3633 - acc: 0.8730 - val_loss: 0.5511 - val_acc: 0.8048\n",
      "Epoch 87/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3620 - acc: 0.8743 - val_loss: 0.5515 - val_acc: 0.8092\n",
      "Epoch 88/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3611 - acc: 0.8740 - val_loss: 0.5528 - val_acc: 0.8110\n",
      "Epoch 89/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3598 - acc: 0.8744 - val_loss: 0.5530 - val_acc: 0.8087\n",
      "Epoch 90/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3588 - acc: 0.8751 - val_loss: 0.5598 - val_acc: 0.8092\n",
      "Epoch 91/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3579 - acc: 0.8758 - val_loss: 0.5531 - val_acc: 0.8087\n",
      "Epoch 92/150\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.3566 - acc: 0.8757 - val_loss: 0.5591 - val_acc: 0.8092\n",
      "Epoch 93/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3556 - acc: 0.8761 - val_loss: 0.5576 - val_acc: 0.8058\n",
      "Epoch 94/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3546 - acc: 0.8761 - val_loss: 0.5568 - val_acc: 0.8085\n",
      "Epoch 95/150\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.3536 - acc: 0.8774 - val_loss: 0.5575 - val_acc: 0.8090\n",
      "Epoch 96/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3526 - acc: 0.8765 - val_loss: 0.5578 - val_acc: 0.8080\n",
      "Epoch 97/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3516 - acc: 0.8778 - val_loss: 0.5572 - val_acc: 0.8098\n",
      "Epoch 98/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3506 - acc: 0.8776 - val_loss: 0.5605 - val_acc: 0.8077\n",
      "Epoch 99/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3496 - acc: 0.8775 - val_loss: 0.5584 - val_acc: 0.8065\n",
      "Epoch 100/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3485 - acc: 0.8781 - val_loss: 0.5664 - val_acc: 0.8062\n",
      "Epoch 101/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3473 - acc: 0.8796 - val_loss: 0.5651 - val_acc: 0.8067\n",
      "Epoch 102/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3468 - acc: 0.8789 - val_loss: 0.5661 - val_acc: 0.8070\n",
      "Epoch 103/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3454 - acc: 0.8791 - val_loss: 0.5660 - val_acc: 0.8060\n",
      "Epoch 104/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3446 - acc: 0.8797 - val_loss: 0.5646 - val_acc: 0.8070\n",
      "Epoch 105/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3434 - acc: 0.8809 - val_loss: 0.5701 - val_acc: 0.8095\n",
      "Epoch 106/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3428 - acc: 0.8805 - val_loss: 0.5662 - val_acc: 0.8075\n",
      "Epoch 107/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3415 - acc: 0.8808 - val_loss: 0.5676 - val_acc: 0.8095\n",
      "Epoch 108/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3402 - acc: 0.8817 - val_loss: 0.5665 - val_acc: 0.8095\n",
      "Epoch 109/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3399 - acc: 0.8816 - val_loss: 0.5670 - val_acc: 0.8037\n",
      "Epoch 110/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.3387 - acc: 0.8818 - val_loss: 0.5688 - val_acc: 0.8085\n",
      "Epoch 111/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3377 - acc: 0.8823 - val_loss: 0.5712 - val_acc: 0.8075\n",
      "Epoch 112/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3368 - acc: 0.8836 - val_loss: 0.5800 - val_acc: 0.8092\n",
      "Epoch 113/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3360 - acc: 0.8829 - val_loss: 0.5682 - val_acc: 0.8073\n",
      "Epoch 114/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3347 - acc: 0.8840 - val_loss: 0.5710 - val_acc: 0.8073\n",
      "Epoch 115/150\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.3342 - acc: 0.8833 - val_loss: 0.5757 - val_acc: 0.8085\n",
      "Epoch 116/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3331 - acc: 0.8847 - val_loss: 0.5783 - val_acc: 0.8040\n",
      "Epoch 117/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3324 - acc: 0.8838 - val_loss: 0.5749 - val_acc: 0.8060\n",
      "Epoch 118/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3314 - acc: 0.8848 - val_loss: 0.5825 - val_acc: 0.8012\n",
      "Epoch 119/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3304 - acc: 0.8850 - val_loss: 0.5774 - val_acc: 0.8023\n",
      "Epoch 120/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3292 - acc: 0.8859 - val_loss: 0.5735 - val_acc: 0.8055\n",
      "Epoch 121/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3284 - acc: 0.8849 - val_loss: 0.5763 - val_acc: 0.8070\n",
      "Epoch 122/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3275 - acc: 0.8860 - val_loss: 0.5839 - val_acc: 0.8055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3265 - acc: 0.8860 - val_loss: 0.5776 - val_acc: 0.8033\n",
      "Epoch 124/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3260 - acc: 0.8868 - val_loss: 0.5797 - val_acc: 0.8062\n",
      "Epoch 125/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3244 - acc: 0.8867 - val_loss: 0.5805 - val_acc: 0.8005\n",
      "Epoch 126/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3238 - acc: 0.8876 - val_loss: 0.5791 - val_acc: 0.8067\n",
      "Epoch 127/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3229 - acc: 0.8883 - val_loss: 0.5814 - val_acc: 0.8020\n",
      "Epoch 128/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3221 - acc: 0.8885 - val_loss: 0.5790 - val_acc: 0.8065\n",
      "Epoch 129/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3210 - acc: 0.8886 - val_loss: 0.5846 - val_acc: 0.8058\n",
      "Epoch 130/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3202 - acc: 0.8887 - val_loss: 0.5833 - val_acc: 0.8035\n",
      "Epoch 131/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3195 - acc: 0.8887 - val_loss: 0.5872 - val_acc: 0.8058\n",
      "Epoch 132/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3185 - acc: 0.8896 - val_loss: 0.5891 - val_acc: 0.8065\n",
      "Epoch 133/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3176 - acc: 0.8898 - val_loss: 0.5836 - val_acc: 0.8073\n",
      "Epoch 134/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3169 - acc: 0.8898 - val_loss: 0.5880 - val_acc: 0.8023\n",
      "Epoch 135/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3161 - acc: 0.8903 - val_loss: 0.5875 - val_acc: 0.8027\n",
      "Epoch 136/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3150 - acc: 0.8909 - val_loss: 0.5851 - val_acc: 0.8073\n",
      "Epoch 137/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3142 - acc: 0.8907 - val_loss: 0.5872 - val_acc: 0.8030\n",
      "Epoch 138/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3135 - acc: 0.8922 - val_loss: 0.5983 - val_acc: 0.8005\n",
      "Epoch 139/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3122 - acc: 0.8920 - val_loss: 0.5929 - val_acc: 0.7985\n",
      "Epoch 140/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3113 - acc: 0.8923 - val_loss: 0.5899 - val_acc: 0.8058\n",
      "Epoch 141/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3104 - acc: 0.8923 - val_loss: 0.5973 - val_acc: 0.8043\n",
      "Epoch 142/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3093 - acc: 0.8928 - val_loss: 0.5978 - val_acc: 0.8008\n",
      "Epoch 143/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3088 - acc: 0.8939 - val_loss: 0.6054 - val_acc: 0.8070\n",
      "Epoch 144/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3080 - acc: 0.8944 - val_loss: 0.5932 - val_acc: 0.8018\n",
      "Epoch 145/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3072 - acc: 0.8945 - val_loss: 0.5968 - val_acc: 0.8035\n",
      "Epoch 146/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3061 - acc: 0.8944 - val_loss: 0.5999 - val_acc: 0.7997\n",
      "Epoch 147/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3052 - acc: 0.8954 - val_loss: 0.5984 - val_acc: 0.8030\n",
      "Epoch 148/150\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3043 - acc: 0.8959 - val_loss: 0.5976 - val_acc: 0.8025\n",
      "Epoch 149/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3032 - acc: 0.8954 - val_loss: 0.6000 - val_acc: 0.7997\n",
      "Epoch 150/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3026 - acc: 0.8953 - val_loss: 0.5989 - val_acc: 0.8050\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['acc'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 1s 697us/step - loss: 0.2984 - acc: 0.8973\n",
      "Training Loss: 0.298 \n",
      "Training Accuracy: 0.897\n",
      "----------\n",
      "125/125 [==============================] - 0s 963us/step - loss: 0.5989 - acc: 0.8050\n",
      "Test Loss: 0.599 \n",
      "Test Accuracy: 0.805\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
